{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN41eYvnSCf70CHUxVc1jgm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhwani123p/MediScripts/blob/main/ML-model/ner/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNcBDQtg67OX",
        "outputId": "49884ebf-4d57-432e-b7d9-d14e12ee649e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchcrf in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchcrf) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchcrf scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_conll(path):\n",
        "    sentences, labels = [], []\n",
        "    words, tags = [], []\n",
        "\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if words:\n",
        "                    sentences.append(words)\n",
        "                    labels.append(tags)\n",
        "                    words, tags = [], []\n",
        "            else:\n",
        "                w, t = line.split()\n",
        "                words.append(w)\n",
        "                tags.append(t)\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "train_sents, train_tags = load_conll(\"/content/synthetic_train (1).conll\")\n",
        "valid_sents, valid_tags = load_conll(\"/content/valid.conll.txt\")\n",
        "\n",
        "print(len(train_sents), len(valid_sents))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA75GEWA7Y4v",
        "outputId": "47963c51-019d-4d5d-9851-cb00447f022d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {\"<PAD>\":0, \"<UNK>\":1}\n",
        "    for s in sentences:\n",
        "        for w in s:\n",
        "            if w not in vocab:\n",
        "                vocab[w] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "word_vocab = build_vocab(train_sents + valid_sents)\n",
        "\n",
        "label_list = sorted({t for seq in train_tags + valid_tags for t in seq})\n",
        "label_to_id = {l:i for i,l in enumerate(label_list)}\n",
        "id_to_label = {i:l for l,i in label_to_id.items()}\n"
      ],
      "metadata": {
        "id": "CGSI0LUY7lgq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def encode(sentences, tags, vocab, label_map):\n",
        "    X, Y, M = [], [], []\n",
        "    max_len = max(len(s) for s in sentences)\n",
        "\n",
        "    for s, t in zip(sentences, tags):\n",
        "        x = [vocab.get(w, vocab[\"<UNK>\"]) for w in s]\n",
        "        y = [label_map[tag] for tag in t]\n",
        "        mask = [1]*len(x)\n",
        "\n",
        "        while len(x) < max_len:\n",
        "            x.append(vocab[\"<PAD>\"])\n",
        "            y.append(0)\n",
        "            mask.append(0)\n",
        "\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "        M.append(mask)\n",
        "\n",
        "    return (\n",
        "        torch.tensor(X),\n",
        "        torch.tensor(Y),\n",
        "        torch.tensor(M, dtype=torch.bool)\n",
        "    )\n",
        "\n",
        "\n",
        "X_train, Y_train, M_train = encode(train_sents, train_tags, word_vocab, label_to_id)\n",
        "X_valid, Y_valid, M_valid = encode(valid_sents, valid_tags, word_vocab, label_to_id)\n"
      ],
      "metadata": {
        "id": "KhSmyPml70al"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, emb_dim=100, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim,\n",
        "            hidden_dim // 2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
        "        self.crf = CRF(tagset_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        emb = self.embedding(x)\n",
        "        out, _ = self.lstm(emb)\n",
        "        emissions = self.fc(out)\n",
        "\n",
        "        if tags is not None:\n",
        "            return -self.crf(emissions, tags, mask=mask)\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dhl6QEU73tX",
        "outputId": "373c5b30-924c-4a08-9fd6-4f81756824a5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.12/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = BiLSTM_CRF(\n",
        "    vocab_size=len(word_vocab),\n",
        "    tagset_size=len(label_to_id)\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(\n",
        "        X_train.to(device),\n",
        "        Y_train.to(device),\n",
        "        mask=M_train.to(device)\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = model(\n",
        "            X_valid.to(device),\n",
        "            Y_valid.to(device),\n",
        "            mask=M_valid.to(device)\n",
        "        ).item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqLXmx9kKzpS",
        "outputId": "61595a65-44cf-4f69-fba7-81df4bf857e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 2371.1060 | Val Loss: 197.8741\n",
            "Epoch 2/10 | Train Loss: 2303.7832 | Val Loss: 193.7629\n",
            "Epoch 3/10 | Train Loss: 2237.2571 | Val Loss: 189.6720\n",
            "Epoch 4/10 | Train Loss: 2170.7812 | Val Loss: 185.5614\n",
            "Epoch 5/10 | Train Loss: 2103.6477 | Val Loss: 181.3959\n",
            "Epoch 6/10 | Train Loss: 2035.2355 | Val Loss: 177.1446\n",
            "Epoch 7/10 | Train Loss: 1965.0325 | Val Loss: 172.7823\n",
            "Epoch 8/10 | Train Loss: 1892.6619 | Val Loss: 168.2902\n",
            "Epoch 9/10 | Train Loss: 1817.9137 | Val Loss: 163.6576\n",
            "Epoch 10/10 | Train Loss: 1740.7722 | Val Loss: 158.8833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"vocab\": word_vocab,\n",
        "    \"label_to_id\": label_to_id\n",
        "}, \"mediscript_ner.pt\")\n"
      ],
      "metadata": {
        "id": "AMi6r23BLD1L"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sents, test_tags = load_conll(\"/content/test.conll.txt\")\n"
      ],
      "metadata": {
        "id": "HiA2Tg4hL-SG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test, M_test = encode(\n",
        "    test_sents,\n",
        "    test_tags,\n",
        "    word_vocab,\n",
        "    label_to_id\n",
        ")\n"
      ],
      "metadata": {
        "id": "g_JJXi2lMCzE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "all_true = []\n",
        "all_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(\n",
        "        X_test.to(device),\n",
        "        mask=M_test.to(device)\n",
        "    )\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    seq_len = M_test[i].sum().item()\n",
        "    true_seq = Y_test[i][:seq_len].tolist()\n",
        "    pred_seq = predictions[i]\n",
        "\n",
        "    all_true.extend(true_seq)\n",
        "    all_pred.extend(pred_seq)\n"
      ],
      "metadata": {
        "id": "ZL5hhjz3MH6r"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [id_to_label[i] for i in all_true]\n",
        "pred_labels = [id_to_label[i] for i in all_pred]\n"
      ],
      "metadata": {
        "id": "1ZaJfYq1MeLZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(\n",
        "    true_labels,\n",
        "    pred_labels,\n",
        "    digits=4\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C45eKeWQMhvX",
        "outputId": "6956ad78-7b49-4608-fdfd-72301597a829"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-DOSE     0.8421    0.7273    0.7805        22\n",
            "      B-DRUG     1.0000    0.5417    0.7027        24\n",
            "       B-DUR     0.7000    0.5000    0.5833        14\n",
            "      B-FREQ     0.6000    0.3750    0.4615        24\n",
            "     B-ROUTE     0.7778    0.7000    0.7368        10\n",
            "      I-DOSE     0.8000    0.9091    0.8511        22\n",
            "      I-DRUG     0.0000    0.0000    0.0000         5\n",
            "       I-DUR     1.0000    0.6923    0.8182        13\n",
            "      I-FREQ     0.5306    0.7879    0.6341        33\n",
            "     I-ROUTE     0.2727    1.0000    0.4286        12\n",
            "           O     0.0000    0.0000    0.0000        14\n",
            "\n",
            "    accuracy                         0.6166       193\n",
            "   macro avg     0.5930    0.5667    0.5452       193\n",
            "weighted avg     0.6523    0.6166    0.6014       193\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Paracetamol 650 mg twice a day for 3 days after food\"\n",
        "\n"
      ],
      "metadata": {
        "id": "LbtZRaWJbgqq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "\n",
        "encoded = [\n",
        "    word_vocab.get(tok, word_vocab[\"<UNK>\"])\n",
        "    for tok in tokens\n",
        "]\n",
        "\n",
        "X = torch.tensor([encoded]).to(device)\n",
        "mask = torch.tensor([[1]*len(encoded)], dtype=torch.bool).to(device)\n"
      ],
      "metadata": {
        "id": "ch2jo-tmcmGf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_ids = model(X, mask=mask)[0]\n"
      ],
      "metadata": {
        "id": "yNXOoIRWctmC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tok, tag_id in zip(tokens, pred_ids):\n",
        "    print(f\"{tok:12} → {id_to_label[tag_id]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94II276Ec0GF",
        "outputId": "b679812a-c062-4d9a-c837-2112792558f2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paracetamol  → B-DRUG\n",
            "650          → B-DOSE\n",
            "mg           → I-DOSE\n",
            "twice        → I-FREQ\n",
            "a            → I-FREQ\n",
            "day          → I-FREQ\n",
            "for          → I-FREQ\n",
            "3            → B-DUR\n",
            "days         → I-DUR\n",
            "after        → B-ROUTE\n",
            "food         → I-ROUTE\n"
          ]
        }
      ]
    }
  ]
}